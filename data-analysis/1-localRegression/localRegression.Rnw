% !TEX TS-program = pgfSweave

\documentclass[11pt,twoside]{article}

%%------------font choices
\usepackage[sc]{mathpazo}
\linespread{1.05}         % Palatino needs more leading (space between lines)

%Sweave
<<sweave,echo=F,results=hide,fig=F,cache=F>>=
if(!file.exists('Sweave.sty'))
	file.copy(file.path(R.home(),'share','texmf','Sweave.sty'),'.')
@
\usepackage[noae,nogin]{Sweave}

%%------------PGF/TIKZ
\usepackage{tikz}

%%------------page layout
\usepackage[left=2cm,top=3cm,right=2cm,bottom=2cm]{geometry} %changes margins
\usepackage[parfill]{parskip} % begin paragraphs with an empty line not indent
\usepackage{multicol}

%%-----------section styles
\usepackage{sectsty}
	%Put period after section number
\sectionfont{\bf\large\raggedright}
\subsectionfont{\bf\normalsize\raggedright}
\subsubsectionfont{\bf}

%%------------graphics
\usepackage{graphicx} 
\usepackage{subfigure}

%%------------mathematics
%\usepackage{amsmath,amssymb,amsthm}

%%------------tables
\usepackage{booktabs}

%%------------misc
\usepackage{verbatim} 
\usepackage[pdftex,bookmarks,colorlinks,breaklinks]{hyperref}
\hypersetup{linkcolor=black,citecolor=black,filecolor=black,urlcolor=black}

%%------------bibliography
\usepackage{natbib}   
%\setcitestyle{square,aysep={},yysep={;}}
\bibliographystyle{agufull04}

%%-----------nicer looking captions
\usepackage[font={bf,small},textfont=md,margin=30pt,aboveskip=0pt,belowskip=0pt]{caption}

%%-----------page header declaration
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\fancyhead[LE,RO]{\thepage}   %page numbers

\fancyhead[CE]{\small CVENxxxx FALL 2009}
\fancyhead[CO]{\small LOCAL POLYNOMIAL REGRESSION}

%\long\def\beginpgfgraphicnamed#1#2\endpgfgraphicnamed{\includegraphics{#1}}
\pgfrealjobname{localRegression} 

\begin{document}

	%Sweave options
\SweaveOpts{echo=F, prefix.string=figs/fig, fig=T, pdf=F, eps=F, pgf=F, tikz=F, external=T}
\thispagestyle{empty} 

\begin{center}
	\textbf{\Large Local Polynomial Regression}
 	{\bf\\ Cameron Bracken \\}
  	CVEN6xxx September, 2009
\end{center}

<<setup,fig=F,echo=F,results=hide,cache=F>>=
	
	suppressMessages(require(tikzDevice))
	suppressMessages(require(pgfSweave))
	suppressMessages(require(xtable))
	suppressMessages(require(locfit))
	suppressMessages(require(fields))
	suppressMessages(require(xtable))
	
	cashdir = "./cache"
	setCacheDir(cashdir)
	
	if(!file.exists('figs')) dir.create('figs')
	
	options('tikzDocumentDeclaration' = '\\documentclass[11pt]{article}')
	nbcol <- 50
	color <- topo.colors(nbcol)

@

<<source,fig=F,echo=F,results=hide,cache=F>>=
	
	setwd('src')
	
		source('libblocfit.R')
		if(!file.exists('output')) 	dir.create('output')
		
		if(file.exists('output/1.Rdata')){
			load('output/1.Rdata')
		}else{
			source('1.R')
		}
		
		if(file.exists('output/2.Rdata')){
			load('output/2.Rdata')
		}else{
			source('2.R')
		}
		
		if(file.exists('output/3.Rdata')){
			load('output/3.Rdata')
		}else{
			source('3.R')
		}
	setwd('..')

@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Problem 1}

The local polynomial regression was as a set of functions which behave exactly like the LOCFIT package.  The \texttt{blocfit()} function initializes the fit object, the \texttt{predict.blocfit()} function estimates the function at arbitrary points by calling \texttt{predict.point()}. Plotting is also done with a method \texttt{plot.blocfit()}.


\VerbatimInput[frame=single]{src/blocfit.R}
\VerbatimInput[frame=single]{src/predict.blocfit.R}
\VerbatimInput[frame=single]{src/predict.point.R}
%,label={Fitting Function},labelposition=all


\VerbatimInput[frame=single]{src/plot.blocfit.R}

The benefit of the object oriented design is usability.  After the methods have been written, customizing the fit is extremely easy. 

i) The resulting hat matrix is shown for the fit when $\alpha=.5$ and $p=1$ for the algorithm implemented and from locfit.  The results match exactly. 

<<fit, echo=T, fig=F, cache=F>>=

blfit1 <- blocfit(oneD$x, oneD$y, a=.5, p=1, kern='bisq')
print(round(blfit1$hat,3))
n <- length(oneD$x)
L <- matrix(NA,nrow=n,ncol=n)
for(i in 1:n){
	L[i,] <- locfit(oneD$y ~ oneD$x, ev=oneD$x[i], alpha=.5, deg=1, kern='bisq',geth=1)
}
print(round(L,3))

@

The highest weight is given to the point where an estimate is made. 

ii) The gcv (which is identical to that obtained with locfit since the hat matrix is the same):
<<gcv, echo=T, fig=F, cache=F>>=

print(blfit1$gcv)

@

iii) \autoref{deg1} shows the resulting fit and confidence intervals when $\alpha=.5$ and $p=1$. The locfit results are not shown because they fall exactly on the line shown. 

\begin{figure}[!ht]
\begin{minipage}{.5\textwidth}
\centering
<<deg1, echo=T, fig=T, tikz=T, cache=T,width=3.5,height=3.5,keep.source=T>>=

blfit1 <- blocfit(oneD$x, oneD$y, 
	a=.5, p=1, kern='bisq')

par(mar = c(2, 2, 2, 2) + 0.1)
plot(blfit1, percent = "\\%")
@
\caption{Sample data with local polynomial fit, $p=\Sexpr{blfit1$p}$, $\alpha=\Sexpr{blfit1$a}$}\label{deg1}
\end{minipage}
\begin{minipage}{.5\textwidth}
\centering
<<linear, echo=T, fig=T, tikz=T, cache=T,width=3.5,height=3.5,keep.source=T>>=

blfit2 <- blocfit(oneD$x, oneD$y, 
	a=1, p=1, kern='none')

par(mar = c(2, 2, 2, 2) + 0.1)
plot(blfit2, percent = "\\%" )		
@
\caption{Sample data with local polynomial fit, $p=\Sexpr{blfit2$p}$, $\alpha=\Sexpr{blfit2$a}$ and uniform weights.}\label{linear}
\end{minipage}
\end{figure}

iv) \autoref{linear} graphically shows that the results of the algorithm are identical to linear regression.  The hat matrices (which are identical) are shown below.  Points everywhere contribute to the weight, furthermore the point nearest to the estimation point does not always contribute the highest weight.
<<hat, echo=T, fig=F, cache=F>>=

print(round(blfit2$hat,3))

X <- cbind(rep(1,n), oneD$x)
lhat <- X %*% solve(t(X) %*% X) %*% t(X)
print(round(lhat,3))

@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section*{Problem 2}

The code which fits the local and linear surface is shown below:

\VerbatimInput[frame=single]{src/2.R}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
i, ii) The surfaces from linear regression and from locfit are shown in figure \autoref{image}
\begin{figure}[!ht]
\centering
<<image, fig=T, tikz=T, external=T, echo=T, keep.source=T, cache=T, width=7.5>>=

layout(matrix(c(1,3,2,4),nrow=2))

my.image <- function(grid, main, x = dem.x, y = dem.y, n = nbcol, ...){
	par(mar = c(4, 4, 2, 4) + 0.1)
	image.plot(y, x, grid, col=topo.colors(nbcol), xlab='Longitude',ylab='Latitude',...)
	contour(y, x, grid, nlevels=4, add=T)
	title(main = main, line=.2)
}

r1 <- range(c(locfitgrid.jan,lmgrid.jan))
r2 <- range(c(locfitgrid.jul,lmgrid.jul))

my.image(locfitgrid.jan,'locfit January', zlim=r1)
my.image(lmgrid.jan,'lm January', zlim=r1)
my.image(locfitgrid.jul,'locfit July', zlim=r2)
my.image(lmgrid.jul,'lm July', zlim=r2)

@
\caption{Precipitation map from locfit and from linear regression for each month}\label{image}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
iii) The Anova results from both models are shown below. 

<<anova, fig=F, echo=T, keep.source=T,results=tex>>=

print(xtable(round(anova(lmfit.jan),2)))
print(xtable(round(anova(lmfit.jul),2)))
anova.locfit(datfit.jan, y.jan, sep='\\\\')
anova.locfit(datfit.jul, y.jul, sep='\\\\')

@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
iv) Observed versus predicted for both model for each month using no validation and drop one cross validation are shown below. 

\begin{figure}[!ht]
\centering
<<validation, fig=T, tikz=T, external=T, echo=T, cache=T>>=

layout(matrix(c(1,3,2,4),nrow=2))

my.plot <- function(y,fit,main,mode=c('full','dropone')){
	par(mar = c(4, 4, 2, 2) + 0.1)
	plot(y, fit, 
		xlab="Observed", 
		ylab=ifelse(mode == "full", 
			"Estimates using full data", "Drop-One Estimates"))
	abline(0,1)
	title(main = main,line=.2)
}

my.plot(y.jan, predict(datfit.jan), 'January', mode = 'full')
my.plot(y.jan, predict(fitcv.jan), 'January', mode = 'dropone')
my.plot(y.jul, predict(datfit.jul), 'July', mode = 'full')
my.plot(y.jul, predict(fitcv.jul), 'July', mode = 'dropone')

@
\caption{Observed versus predicted for Locfit model using full data and drop-one cross validation.}\label{validation}
\end{figure}

\begin{figure}[!ht]
\centering
<<validation-lm, fig=T, tikz=T, external=T, echo=T, cache=T>>=

layout(matrix(c(1,3,2,4),nrow=2))

my.plot(y.jan, predict(lmfit.jan), 'January', mode = 'full')
my.plot(y.jan, lmpred.cv.jan, 'January', mode = 'dropone')
my.plot(y.jul, predict(lmfit.jul), 'July', mode = 'full')
my.plot(y.jul, lmpred.cv.jul, 'July', mode = 'dropone')

@
\caption{Observed versus predicted for linear model using full data and drop-one cross validation. The January model was poor at capturing low and high values.}\label{validation-lm}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
v) Surface plots of predictions from both models are shown below.
\begin{figure}[!ht]
\centering
<<persp, fig=T, tikz=T, external=T, echo=T, cache=T>>=

layout(matrix(c(1,3,2,4),nrow=2))

my.persp <- function(grid, main, x = dem.x, y = dem.y, cf = colf){
	par(mar=c(0,1,0,0))
	persp(y, x, grid,
		col=color[cf(grid)],
		xlab='Longitude',
		ylab='Latitude', 
		zlab = 'Rainfall',
		theta=30, phi=30, expand=0.5,
		shade=0.5, ltheta=-30)
	title(main=main,line=-2)
}

my.persp(locfitgrid.jan,'locfit January')
my.persp(lmgrid.jan,'lm January')
my.persp(locfitgrid.jul,'locfit July')
my.persp(lmgrid.jul,'lm July')
	
@
\caption{Surface plots of rainfall from locfit and from the linear model.}\label{persp}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
vi) Plots of the error are shown below. 
\begin{figure}[!ht]
\centering
<<image-error, fig=T, tikz=T, external=T, echo=T, keep.source=T, cache=T, width=7.5>>=

layout(matrix(c(1,3,2,4),nrow=2))

my.image(locfitgrid.se.jan,'locfit January')
my.image(lmgrid.se.jan,'lm January')
my.image(locfitgrid.se.jul,'locfit July')
my.image(lmgrid.se.jul,'lm July')

@
%r1 <- range(c(locfitgrid.se.jan,lmgrid.se.jan))
%r2 <- range(c(locfitgrid.se.jul,lmgrid.se.jul))

\caption{Precipitation error map.  Interestingly, the magnitude of the error in the linear model is much less than with locfit. Error increases around the edges with both methods.  }\label{image-error}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
viii) The best parameters for january are shown below using both GCV and AIC. For this set of predictors the parameters are the same for both criteria.  This may be a consequence of the data being very noisy and the smallest smoothing parameter always giving the best fit. The best model turns out to be the one with all three predictors, which gives the most information. 

<<best, echo=T, fig=F, cache=F>>=

print(best.jul)
print(best.jul.aic)

@

Table below show the different combinations of predictor variables, in both cases (using aic and gcv), the best model was that which used all three predictors and so it us identical to the one used previously. 

<<best-models, echo=T, fig=F,results=tex, cache=F>>=

print(xtable(matrix(as.integer(best.models.jul$which),ncol=3)))
print(xtable(best.models.jul$par))
print(xtable(best.models.jul.aic$par))

@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section*{Problem 3}

i) ii)  The code to fit the local and global glm is shown below

\VerbatimInput[frame=single]{src/3.R}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
iii) Some model diagnostics are shown below.
<<glm-tab, fig=F, echo=T, keep.source=T,results=tex>>=

print(xtable(summary(gfit.11)))
print(xtable(summary(gfit.12)))
print(xtable(summary(gfit.13)))

@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
iv) The precipitation probability maps are shown below for the global and local glm for each day. 
\begin{figure}[!ht]
\centering
<<image-glm, fig=T, tikz=T, external=T, echo=T, cache=T, width=7,height=8>>=

layout(matrix(1:6,nrow=3,byrow=T))

my.image(ggrid.11, 'global glm 11th',zlim=c(0,1))
my.image(lggrid.11,'local glm 11th',zlim=c(0,1))
my.image(ggrid.12, 'global glm 12th',zlim=c(0,1))
my.image(lggrid.12,'local glm 12th',zlim=c(0,1))
my.image(ggrid.13, 'global glm 13th',zlim=c(0,1))
my.image(lggrid.13,'local glm 13th',zlim=c(0,1))

@
%r1 <- range(c(locfitgrid.se.jan,lmgrid.se.jan))
%r2 <- range(c(locfitgrid.se.jul,lmgrid.se.jul))

\caption{Precipitation probability map for the three days using both global and local glm models. }\label{image-error}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
v)  Similar patterns of precipitation probability can be seen as in Slater and Clark (2006) though an exact comparison is difficult without the data set. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
vi) The best models using both the AIC criteria and the GCV criteria are shown below for the 11th. The first table gives the predictor sets and the second two tables give the optimal parameters for each predictor set.  In both cases the model which includes all three predictors is the best fit. The `best model' here is identical to the one used in ii. because all the predictors were used there as well.  With the glm, using both local and global did not change the precipitation probability estimates much. 

<<best-models-glm, echo=T, fig=F,results=tex, cache=F>>=

print(xtable(matrix(as.integer(best.models.11$which),ncol=3)))
print(xtable(best.models.11$par))
print(xtable(best.models.11.aic$par))

@

\clearpage
\nocite{Loader1999}
\bibliography{references}

\end{document}






